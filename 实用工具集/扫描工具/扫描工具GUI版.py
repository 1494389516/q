#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰«æå·¥å…·2.5 - å›¾å½¢ç•Œé¢ç‰ˆæœ¬
é›†æˆJSFinderåŠŸèƒ½çš„ç»¼åˆæ‰«æå·¥å…·
"""

import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox, filedialog
import threading
import requests
from bs4 import BeautifulSoup
import urllib.parse
import re
import nmap
import whois
import sublist3r
import dns.resolver
import ssl
from cryptography import x509
from cryptography.hazmat.backends import default_backend
import datetime
import subprocess
import time
from urllib3 import disable_warnings
from urllib3.exceptions import InsecureRequestWarning

# ç¦ç”¨SSLè­¦å‘Š
disable_warnings(InsecureRequestWarning)

class ScanToolGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("æ‰«æå·¥å…·2.5 - å›¾å½¢ç•Œé¢ç‰ˆ")
        self.root.geometry("1000x700")
        self.root.resizable(True, True)
        
        # è®¾ç½®å›¾æ ‡ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
        try:
            self.root.iconbitmap("icon.ico")
        except:
            pass
        
        self.setup_ui()
        self.current_function = None
        
    def setup_ui(self):
        """è®¾ç½®ç”¨æˆ·ç•Œé¢"""
        # åˆ›å»ºä¸»æ¡†æ¶
        main_frame = ttk.Frame(self.root)
        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)
        
        # åˆ›å»ºå·¦ä¾§åŠŸèƒ½é€‰æ‹©æ¡†æ¶
        left_frame = ttk.Frame(main_frame, width=200)
        left_frame.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 10))
        left_frame.pack_propagate(False)
        
        # æ ‡é¢˜
        title_label = ttk.Label(left_frame, text="æ‰«æå·¥å…·2.5", font=("Arial", 16, "bold"))
        title_label.pack(pady=(0, 10))
        
        # åŠŸèƒ½é€‰æ‹©æ ‡ç­¾
        ttk.Label(left_frame, text="é€‰æ‹©æ‰«æåŠŸèƒ½:", font=("Arial", 12, "bold")).pack(pady=(0, 10))
        
        # åŠŸèƒ½æŒ‰é’®
        self.create_function_buttons(left_frame)
        
        # åˆ›å»ºå³ä¾§è¾“å…¥å’Œç»“æœæ¡†æ¶
        right_frame = ttk.Frame(main_frame)
        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)
        
        # è¾“å…¥æ¡†æ¶
        input_frame = ttk.LabelFrame(right_frame, text="è¾“å…¥å‚æ•°", padding=10)
        input_frame.pack(fill=tk.X, pady=(0, 10))
        
        # URLè¾“å…¥
        ttk.Label(input_frame, text="ç›®æ ‡URL/IP/åŸŸå:").pack(anchor=tk.W)
        self.url_entry = ttk.Entry(input_frame, width=80, font=("Consolas", 10))
        self.url_entry.pack(fill=tk.X, pady=(5, 10))
        
        # Cookieè¾“å…¥
        ttk.Label(input_frame, text="Cookie (å¯é€‰):").pack(anchor=tk.W)
        self.cookie_entry = ttk.Entry(input_frame, width=80, font=("Consolas", 10))
        self.cookie_entry.pack(fill=tk.X, pady=(5, 10))
        
        # å…¶ä»–å‚æ•°è¾“å…¥
        ttk.Label(input_frame, text="å…¶ä»–å‚æ•° (å¯é€‰):").pack(anchor=tk.W)
        self.params_entry = ttk.Entry(input_frame, width=80, font=("Consolas", 10))
        self.params_entry.pack(fill=tk.X, pady=(5, 10))
        
        # æŒ‰é’®æ¡†æ¶
        button_frame = ttk.Frame(input_frame)
        button_frame.pack(fill=tk.X, pady=10)
        
        # æ‰§è¡ŒæŒ‰é’®
        self.execute_btn = ttk.Button(button_frame, text="æ‰§è¡Œæ‰«æ", command=self.execute_scan)
        self.execute_btn.pack(side=tk.LEFT, padx=(0, 10))
        
        # åœæ­¢æŒ‰é’®
        self.stop_btn = ttk.Button(button_frame, text="åœæ­¢æ‰«æ", command=self.stop_scan, state="disabled")
        self.stop_btn.pack(side=tk.LEFT, padx=(0, 10))
        
        # æ¸…ç©ºæŒ‰é’®
        clear_btn = ttk.Button(button_frame, text="æ¸…ç©ºç»“æœ", command=self.clear_results)
        clear_btn.pack(side=tk.LEFT, padx=(0, 10))
        
        # ä¿å­˜æŒ‰é’®
        save_btn = ttk.Button(button_frame, text="ä¿å­˜ç»“æœ", command=self.save_results)
        save_btn.pack(side=tk.LEFT)
        
        # ç»“æœæ˜¾ç¤ºæ¡†æ¶
        result_frame = ttk.LabelFrame(right_frame, text="æ‰«æç»“æœ", padding=5)
        result_frame.pack(fill=tk.BOTH, expand=True)
        
        # ç»“æœæ–‡æœ¬æ¡†
        self.result_text = scrolledtext.ScrolledText(
            result_frame, 
            wrap=tk.WORD, 
            font=("Consolas", 10),
            bg="#1e1e1e",
            fg="#ffffff",
            insertbackground="#ffffff"
        )
        self.result_text.pack(fill=tk.BOTH, expand=True)
        
        # è¿›åº¦æ¡
        self.progress = ttk.Progressbar(self.root, mode='indeterminate')
        self.progress.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=(0, 5))
        
        # çŠ¶æ€æ 
        self.status_var = tk.StringVar()
        self.status_var.set("å°±ç»ª - è¯·é€‰æ‹©æ‰«æåŠŸèƒ½")
        status_bar = ttk.Label(self.root, textvariable=self.status_var, relief=tk.SUNKEN, anchor=tk.W)
        status_bar.pack(side=tk.BOTTOM, fill=tk.X, padx=10, pady=(0, 5))
        
        # æ‰«ææ§åˆ¶
        self.scan_thread = None
        self.stop_scanning = False
    
    def create_function_buttons(self, parent):
        """åˆ›å»ºåŠŸèƒ½æŒ‰é’®"""
        functions = [
            ("ğŸ” JSFinderæ‰«æ", "jsfinder", "#4CAF50"),
            ("ğŸ”Œ ç«¯å£æ‰«æ", "port_scan", "#2196F3"),
            ("ğŸ“‹ WHOISæŸ¥è¯¢", "whois", "#FF9800"),
            ("ğŸŒ ShodanæŸ¥è¯¢", "shodan", "#9C27B0"),
            ("ğŸ” Nmapæ‰«æ", "nmap", "#607D8B"),
            ("ğŸ“„ è·å–ç½‘é¡µ", "webpage", "#795548"),
            ("ğŸŒ³ å­åŸŸåæšä¸¾", "subdomain", "#009688"),
            ("ğŸ” DNSæŸ¥è¯¢", "dns", "#3F51B5"),
            ("ğŸ›¡ï¸ Webå®‰å…¨æµ‹è¯•", "websec", "#F44336"),
            ("ğŸ“Š ä¿¡æ¯æ”¶é›†", "harvest", "#E91E63"),
            ("ğŸ”’ SSLè¯ä¹¦", "ssl", "#00BCD4"),
            ("ğŸ•·ï¸ ç½‘ç«™çˆ¬å–", "crawl", "#8BC34A"),
            ("âš¡ æ‰‹å·¥æµ‹è¯•", "manual", "#FFC107"),
            ("ğŸ”§ è®¾ç½®ä»£ç†", "proxy", "#9E9E9E")
        ]
        
        for text, func, color in functions:
            btn = ttk.Button(
                parent, 
                text=text, 
                width=20,
                command=lambda f=func: self.select_function(f)
            )
            btn.pack(pady=3, fill=tk.X)
    
    def select_function(self, function):
        """é€‰æ‹©åŠŸèƒ½"""
        self.current_function = function
        self.status_var.set(f"å·²é€‰æ‹©: {function}")
        
        # æ¸…ç©ºè¾“å…¥æ¡†å¹¶è®¾ç½®é»˜è®¤å€¼
        self.url_entry.delete(0, tk.END)
        self.cookie_entry.delete(0, tk.END)
        self.params_entry.delete(0, tk.END)
        
        # æ ¹æ®åŠŸèƒ½ç±»å‹è°ƒæ•´ç•Œé¢
        if function == "jsfinder":
            self.url_entry.insert(0, "baidu.com")
            messagebox.showinfo("JSFinder", "JSFinderåŠŸèƒ½å¯ä»¥ä»ç½‘é¡µä¸­æå–URLå’Œå­åŸŸå\næ”¯æŒè¾“å…¥åŸŸåæˆ–å®Œæ•´URL")
        elif function == "port_scan" or function == "nmap":
            self.url_entry.insert(0, "127.0.0.1")
        elif function == "whois":
            self.url_entry.insert(0, "baidu.com")
        elif function == "ssl":
            self.url_entry.insert(0, "https://www.baidu.com")
        else:
            self.url_entry.insert(0, "www.baidu.com")
    
    def execute_scan(self):
        """æ‰§è¡Œæ‰«æ"""
        if not self.current_function:
            messagebox.showwarning("è­¦å‘Š", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ªæ‰«æåŠŸèƒ½")
            return
        
        target = self.url_entry.get().strip()
        if not target:
            messagebox.showwarning("è­¦å‘Š", "è¯·è¾“å…¥ç›®æ ‡URL/IP/åŸŸå")
            return
        
        # æ¸…ç©ºç»“æœæ˜¾ç¤º
        self.result_text.delete(1.0, tk.END)
        self.status_var.set("æ­£åœ¨æ‰«æ...")
        self.execute_btn.config(state="disabled")
        self.stop_btn.config(state="normal")
        self.progress.start()
        self.stop_scanning = False
        
        # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œæ‰«æ
        self.scan_thread = threading.Thread(target=self.run_scan, args=(target,))
        self.scan_thread.daemon = True
        self.scan_thread.start()
    
    def stop_scan(self):
        """åœæ­¢æ‰«æ"""
        self.stop_scanning = True
        self.status_var.set("æ­£åœ¨åœæ­¢æ‰«æ...")
    
    def clear_results(self):
        """æ¸…ç©ºç»“æœ"""
        self.result_text.delete(1.0, tk.END)
        self.status_var.set("ç»“æœå·²æ¸…ç©º")
    
    def save_results(self):
        """ä¿å­˜ç»“æœ"""
        content = self.result_text.get(1.0, tk.END)
        if not content.strip():
            messagebox.showwarning("è­¦å‘Š", "æ²¡æœ‰ç»“æœå¯ä¿å­˜")
            return
        
        filename = filedialog.asksaveasfilename(
            defaultextension=".txt",
            filetypes=[("æ–‡æœ¬æ–‡ä»¶", "*.txt"), ("æ‰€æœ‰æ–‡ä»¶", "*.*")]
        )
        
        if filename:
            try:
                with open(filename, 'w', encoding='utf-8') as f:
                    f.write(content)
                messagebox.showinfo("æˆåŠŸ", f"ç»“æœå·²ä¿å­˜åˆ°: {filename}")
            except Exception as e:
                messagebox.showerror("é”™è¯¯", f"ä¿å­˜å¤±è´¥: {str(e)}")
    
    def run_scan(self, target):
        """åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œæ‰«æ"""
        try:
            if self.current_function == "jsfinder":
                cookie = self.cookie_entry.get().strip() or None
                results = self.js_finder_scan(target, cookie)
                
                if results and not self.stop_scanning:
                    output = f"ğŸ” JSFinderæ‰«æç»“æœ\n{'='*50}\n\n"
                    output += f"ğŸ“Š æ‰¾åˆ° {len(results['urls'])} ä¸ªURL:\n"
                    for i, url in enumerate(results['urls'], 1):
                        if self.stop_scanning:
                            break
                        output += f"  {i:3d}. {url}\n"
                    
                    output += f"\nğŸŒ æ‰¾åˆ° {len(results['subdomains'])} ä¸ªå­åŸŸå:\n"
                    for i, subdomain in enumerate(results['subdomains'], 1):
                        if self.stop_scanning:
                            break
                        output += f"  {i:3d}. {subdomain}\n"
                else:
                    output = "âŒ JSFinderæ‰«ææœªè¿”å›ç»“æœæˆ–å‘ç”Ÿé”™è¯¯"
            
            elif self.current_function == "port_scan":
                results = self.scan_ports(target)
                if results and not self.stop_scanning:
                    output = f"ğŸ”Œ ç«¯å£æ‰«æç»“æœ\n{'='*50}\n\n"
                    for item in results:
                        if self.stop_scanning:
                            break
                        output += f"âœ… {item}\n"
                else:
                    output = "âŒ ç«¯å£æ‰«ææœªè¿”å›ç»“æœæˆ–å‘ç”Ÿé”™è¯¯"
            
            elif self.current_function == "whois":
                results = self.query_whois(target)
                if results and not self.stop_scanning:
                    output = f"ğŸ“‹ WHOISæŸ¥è¯¢ç»“æœ\n{'='*50}\n\n"
                    for key, value in results.items():
                        if self.stop_scanning:
                            break
                        output += f"ğŸ“Œ {key}: {value}\n"
                else:
                    output = "âŒ WHOISæŸ¥è¯¢æœªè¿”å›ç»“æœæˆ–å‘ç”Ÿé”™è¯¯"
            
            elif self.current_function == "subdomain":
                results = self.subdomain_enum(target)
                if results and not self.stop_scanning:
                    output = f"ğŸŒ³ å­åŸŸåæšä¸¾ç»“æœ\n{'='*50}\n\n"
                    for i, subdomain in enumerate(results, 1):
                        if self.stop_scanning:
                            break
                        output += f"  {i:3d}. {subdomain}\n"
                else:
                    output = "âŒ å­åŸŸåæšä¸¾æœªè¿”å›ç»“æœæˆ–å‘ç”Ÿé”™è¯¯"
            
            elif self.current_function == "ssl":
                results = self.get_ssl_info(target)
                if results and not self.stop_scanning:
                    output = f"ğŸ”’ SSLè¯ä¹¦ä¿¡æ¯\n{'='*50}\n\n"
                    for key, value in results.items():
                        if self.stop_scanning:
                            break
                        output += f"ğŸ” {key}: {value}\n"
                else:
                    output = "âŒ SSLè¯ä¹¦æŸ¥è¯¢æœªè¿”å›ç»“æœæˆ–å‘ç”Ÿé”™è¯¯"
            
            elif self.current_function == "dns":
                results = self.get_dns_records(target)
                if results and not self.stop_scanning:
                    output = f"ğŸ” DNSæŸ¥è¯¢ç»“æœ\n{'='*50}\n\n"
                    for key, value in results.items():
                        if self.stop_scanning:
                            break
                        output += f"ğŸ“ {key}: {value}\n"
                else:
                    output = "âŒ DNSæŸ¥è¯¢æœªè¿”å›ç»“æœæˆ–å‘ç”Ÿé”™è¯¯"
            
            elif self.current_function == "webpage":
                results = self.get_web_page(target)
                if results and not self.stop_scanning:
                    output = f"ğŸ“„ ç½‘é¡µå†…å®¹ (å‰2000å­—ç¬¦)\n{'='*50}\n\n{results[:2000]}..."
                else:
                    output = "âŒ æ— æ³•è·å–ç½‘é¡µå†…å®¹"
            
            else:
                output = f"âš ï¸ åŠŸèƒ½ {self.current_function} æ­£åœ¨å¼€å‘ä¸­..."
            
            if self.stop_scanning:
                output += "\n\nâ¹ï¸ æ‰«æå·²è¢«ç”¨æˆ·åœæ­¢"
            
            # åœ¨ä¸»çº¿ç¨‹ä¸­æ›´æ–°UI
            self.root.after(0, self.update_result, output)
            
        except Exception as e:
            error_msg = f"âŒ æ‰«æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            self.root.after(0, self.update_result, error_msg)
    
    def update_result(self, output):
        """æ›´æ–°ç»“æœæ˜¾ç¤º"""
        self.result_text.delete(1.0, tk.END)
        self.result_text.insert(1.0, output)
        self.status_var.set("æ‰«æå®Œæˆ" if not self.stop_scanning else "æ‰«æå·²åœæ­¢")
        self.execute_btn.config(state="normal")
        self.stop_btn.config(state="disabled")
        self.progress.stop()
    
    def append_result(self, text):
        """è¿½åŠ ç»“æœåˆ°æ˜¾ç¤ºåŒºåŸŸ"""
        self.result_text.insert(tk.END, text + "\n")
        self.result_text.see(tk.END)
        self.root.update_idletasks()
    
    # æ‰«æåŠŸèƒ½å®ç°
    def js_finder_scan(self, target, cookie=None):
        """JSFinderæ‰«æåŠŸèƒ½"""
        try:
            # å¤„ç†è¾“å…¥çš„ç›®æ ‡ï¼Œç¡®ä¿æ˜¯å®Œæ•´çš„URL
            if not target.startswith(('http://', 'https://')):
                target = f"https://{target}"
            
            self.append_result(f"[*] æ­£åœ¨æ‰«æç›®æ ‡: {target}")
            
            # è·å–ç½‘é¡µæºç 
            html_content = self.get_webpage_content(target, cookie)
            if not html_content:
                self.append_result(f"[-] æ— æ³•è®¿é—® {target}")
                return None
            
            self.append_result(f"[+] æˆåŠŸè·å–ç½‘é¡µå†…å®¹ï¼Œé•¿åº¦: {len(html_content)} å­—ç¬¦")
            
            # è§£æHTMLå¹¶æå–æ‰€æœ‰è„šæœ¬å†…å®¹
            all_scripts = self.extract_all_scripts(target, html_content, cookie)
            self.append_result(f"[+] æ€»å…±å¤„ç†äº† {len(all_scripts)} ä¸ªè„šæœ¬æº")
            
            # ä»æ‰€æœ‰è„šæœ¬ä¸­æå–URL
            all_urls = []
            for script_info in all_scripts:
                if self.stop_scanning:
                    break
                urls = self.extract_urls_from_script(script_info['content'])
                if urls:
                    self.append_result(f"[+] ä» {script_info['source']} ä¸­æå–åˆ° {len(urls)} ä¸ªURL")
                    for url in urls:
                        processed_url = self.normalize_url(target, url)
                        if processed_url:
                            all_urls.append(processed_url)
            
            self.append_result(f"[+] æ€»å…±æå–åˆ° {len(all_urls)} ä¸ªURL")
            
            # è¿‡æ»¤å’Œåˆ†ç±»URL
            filtered_results = self.filter_and_classify_urls(target, all_urls)
            
            self.append_result(f"[+] è¿‡æ»¤åä¿ç•™ {len(filtered_results['urls'])} ä¸ªç›¸å…³URL")
            self.append_result(f"[+] å‘ç° {len(filtered_results['subdomains'])} ä¸ªå­åŸŸå")
            
            return filtered_results
            
        except Exception as e:
            self.append_result(f"[-] JSFinderæ‰«æé”™è¯¯: {str(e)}")
            return None
    
    def get_webpage_content(self, url, cookie=None):
        """è·å–ç½‘é¡µå†…å®¹"""
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1"
        }
        
        if cookie:
            headers["Cookie"] = cookie
        
        try:
            response = requests.get(url, headers=headers, timeout=15, verify=False, allow_redirects=True)
            response.raise_for_status()
            
            if response.encoding == 'ISO-8859-1':
                response.encoding = response.apparent_encoding
            
            return response.text
            
        except requests.exceptions.RequestException as e:
            self.append_result(f"[-] è¯·æ±‚å¤±è´¥: {str(e)}")
            return None
    
    def extract_all_scripts(self, base_url, html_content, cookie=None):
        """æå–æ‰€æœ‰è„šæœ¬å†…å®¹"""
        scripts = []
        
        try:
            soup = BeautifulSoup(html_content, "html.parser")
            script_tags = soup.find_all("script")
            
            # å¤„ç†å†…è”è„šæœ¬
            inline_content = ""
            for script in script_tags:
                if not script.get("src"):
                    content = script.get_text()
                    if content.strip():
                        inline_content += content + "\n"
            
            if inline_content.strip():
                scripts.append({
                    'source': base_url + " (inline)",
                    'content': inline_content
                })
            
            # å¤„ç†å¤–éƒ¨è„šæœ¬
            for script in script_tags:
                if self.stop_scanning:
                    break
                src = script.get("src")
                if src:
                    external_url = self.normalize_url(base_url, src)
                    if external_url:
                        external_content = self.get_webpage_content(external_url, cookie)
                        if external_content:
                            scripts.append({
                                'source': external_url,
                                'content': external_content
                            })
        
        except Exception as e:
            self.append_result(f"[-] è„šæœ¬æå–é”™è¯¯: {str(e)}")
        
        return scripts
    
    def extract_urls_from_script(self, script_content):
        """ä»è„šæœ¬å†…å®¹ä¸­æå–URL"""
        if not script_content:
            return []
        
        urls = []
        
        patterns = [
            r'(?:"|\'|`)(https?://[^"\'`\s<>]+)(?:"|\'|`)',
            r'(?:"|\'|`)(/[^"\'`\s<>]*\.(?:php|asp|aspx|jsp|html|htm|js|css|json|xml|txt|action))(?:"|\'|`)',
            r'(?:"|\'|`)(/api/[^"\'`\s<>]+)(?:"|\'|`)',
            r'(?:"|\'|`)(/[a-zA-Z0-9_\-/]+/[a-zA-Z0-9_\-/]*\.?[a-zA-Z0-9]*(?:\?[^"\'`\s<>]*)?)(?:"|\'|`)',
            r'(?:"|\'|`)([a-zA-Z0-9](?:[a-zA-Z0-9\-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}(?:"|\'|`)',
        ]
        
        for pattern in patterns:
            try:
                matches = re.findall(pattern, script_content, re.IGNORECASE)
                for match in matches:
                    if isinstance(match, tuple):
                        match = match[0] if match[0] else (match[1] if len(match) > 1 else "")
                    
                    if match and len(match) > 1:
                        if not any(blackword in match.lower() for blackword in ['javascript:', 'data:', 'mailto:', 'tel:']):
                            urls.append(match)
            except Exception:
                continue
        
        return list(set(urls))
    
    def normalize_url(self, base_url, relative_url):
        """æ ‡å‡†åŒ–URL"""
        try:
            if not relative_url:
                return None
            
            if relative_url.startswith(('http://', 'https://')):
                return relative_url
            
            if relative_url.startswith('//'):
                base_parsed = urllib.parse.urlparse(base_url)
                return f"{base_parsed.scheme}:{relative_url}"
            
            if relative_url.startswith('/'):
                base_parsed = urllib.parse.urlparse(base_url)
                return f"{base_parsed.scheme}://{base_parsed.netloc}{relative_url}"
            
            return urllib.parse.urljoin(base_url, relative_url)
            
        except Exception:
            return None
    
    def filter_and_classify_urls(self, base_url, urls):
        """è¿‡æ»¤å’Œåˆ†ç±»URL"""
        try:
            base_parsed = urllib.parse.urlparse(base_url)
            base_domain = base_parsed.netloc.lower()
            
            domain_parts = base_domain.split('.')
            if len(domain_parts) >= 2:
                main_domain = '.'.join(domain_parts[-2:])
            else:
                main_domain = base_domain
            
            filtered_urls = []
            subdomains = set()
            
            for url in urls:
                try:
                    parsed = urllib.parse.urlparse(url)
                    url_domain = parsed.netloc.lower()
                    
                    if main_domain in url_domain or not url_domain:
                        if url not in filtered_urls:
                            filtered_urls.append(url)
                        
                        if url_domain and main_domain in url_domain:
                            subdomains.add(url_domain)
                            
                except Exception:
                    continue
            
            return {
                'urls': filtered_urls,
                'subdomains': sorted(list(subdomains))
            }
            
        except Exception as e:
            self.append_result(f"[-] URLè¿‡æ»¤é”™è¯¯: {str(e)}")
            return {'urls': [], 'subdomains': []}
    
    def scan_ports(self, target):
        """ç«¯å£æ‰«æ"""
        try:
            nm = nmap.PortScanner()
            self.append_result(f"[*] æ­£åœ¨æ‰«æ {target} çš„ç«¯å£...")
            nm.scan(target, arguments='-sS')
            
            results = []
            for host in nm.all_hosts():
                if self.stop_scanning:
                    break
                for proto in nm[host].all_protocols():
                    ports = nm[host][proto].keys()
                    for port in ports:
                        if self.stop_scanning:
                            break
                        service = nm[host][proto][port]['name']
                        state = nm[host][proto][port]['state']
                        results.append(f"{host} çš„ {proto.upper()}ç«¯å£ {port} {state} - {service}")
            return results
        except Exception as e:
            self.append_result(f"[-] ç«¯å£æ‰«æé”™è¯¯: {str(e)}")
            return None
    
    def query_whois(self, domain):
        """WHOISæŸ¥è¯¢"""
        try:
            self.append_result(f"[*] æ­£åœ¨æŸ¥è¯¢ {domain} çš„WHOISä¿¡æ¯...")
            w = whois.whois(domain)
            return {
                'åŸŸå': w.domain,
                'æ³¨å†Œå•†': w.registrar,
                'åˆ›å»ºæ—¥æœŸ': w.creation_date,
                'è¿‡æœŸæ—¥æœŸ': w.expiration_date,
                'åç§°æœåŠ¡å™¨': w.name_servers,
                'çŠ¶æ€': w.status
            }
        except Exception as e:
            self.append_result(f"[-] WHOISæŸ¥è¯¢é”™è¯¯: {str(e)}")
            return None
    
    def subdomain_enum(self, domain):
        """å­åŸŸåæšä¸¾"""
        try:
            self.append_result(f"[*] æ­£åœ¨æšä¸¾ {domain} çš„å­åŸŸå...")
            subdomains = sublist3r.main(domain, 40, None, ports=None, silent=True, verbose=False, enable_bruteforce=False, engines=None)
            return subdomains
        except Exception as e:
            self.append_result(f"[-] å­åŸŸåæšä¸¾é”™è¯¯: {str(e)}")
            return None
    
    def get_ssl_info(self, url):
        """è·å–SSLè¯ä¹¦ä¿¡æ¯"""
        try:
            hostname = url.replace('https://', '').replace('http://', '').split('/')[0]
            self.append_result(f"[*] æ­£åœ¨è·å– {hostname} çš„SSLè¯ä¹¦ä¿¡æ¯...")
            cert = ssl.get_server_certificate((hostname, 443))
            cert_obj = x509.load_pem_x509_certificate(cert.encode(), default_backend())
            
            issuer = cert_obj.issuer.rfc4514_string()
            subject = cert_obj.subject.rfc4514_string()
            valid_from = cert_obj.not_valid_before
            valid_to = cert_obj.not_valid_after
            
            return {
                'é¢å‘æœºæ„': issuer,
                'ä¸»ä½“': subject,
                'æœ‰æ•ˆæœŸä»': valid_from.strftime('%Y-%m-%d'),
                'æœ‰æ•ˆæœŸè‡³': valid_to.strftime('%Y-%m-%d')
            }
        except Exception as e:
            self.append_result(f"[-] SSLè¯ä¹¦æŸ¥è¯¢é”™è¯¯: {str(e)}")
            return None
    
    def get_dns_records(self, domain):
        """è·å–DNSè®°å½•"""
        try:
            self.append_result(f"[*] æ­£åœ¨æŸ¥è¯¢ {domain} çš„DNSè®°å½•...")
            records = {}
            
            # Aè®°å½•
            try:
                a_records = dns.resolver.resolve(domain, 'A')
                records['Aè®°å½•'] = [str(r) for r in a_records]
            except:
                records['Aè®°å½•'] = ['æŸ¥è¯¢å¤±è´¥']
            
            # MXè®°å½•
            try:
                mx_records = dns.resolver.resolve(domain, 'MX')
                records['MXè®°å½•'] = [str(r.exchange) for r in mx_records]
            except:
                records['MXè®°å½•'] = ['æŸ¥è¯¢å¤±è´¥']
            
            # NSè®°å½•
            try:
                ns_records = dns.resolver.resolve(domain, 'NS')
                records['NSè®°å½•'] = [str(r) for r in ns_records]
            except:
                records['NSè®°å½•'] = ['æŸ¥è¯¢å¤±è´¥']
            
            return records
        except Exception as e:
            self.append_result(f"[-] DNSæŸ¥è¯¢é”™è¯¯: {str(e)}")
            return None
    
    def get_web_page(self, url):
        """è·å–ç½‘é¡µå†…å®¹"""
        try:
            self.append_result(f"[*] æ­£åœ¨è·å– {url} çš„ç½‘é¡µå†…å®¹...")
            response = requests.get(url, timeout=10, verify=False)
            response.raise_for_status()
            return response.text
        except Exception as e:
            self.append_result(f"[-] è·å–ç½‘é¡µå†…å®¹é”™è¯¯: {str(e)}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    root = tk.Tk()
    app = ScanToolGUI(root)
    
    # è®¾ç½®çª—å£å±…ä¸­
    root.update_idletasks()
    width = root.winfo_width()
    height = root.winfo_height()
    x = (root.winfo_screenwidth() // 2) - (width // 2)
    y = (root.winfo_screenheight() // 2) - (height // 2)
    root.geometry(f"{width}x{height}+{x}+{y}")
    
    root.mainloop()

if __name__ == "__main__":
    main()